{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNl49mi+V9MK4ER1GwPQqFX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"7a08e9460b764b06bc81d49c8d32dc58":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_599bb6fb5e424e428c8e287afc092218","IPY_MODEL_02d6e2800fdc4949a8fd98ca1ce1616a","IPY_MODEL_4076f6f7080444b2816076fbff238b4b"],"layout":"IPY_MODEL_40bc2c100cd4422cba87c486bba059e9"}},"599bb6fb5e424e428c8e287afc092218":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15128b176c60435ca44a040bf46c2615","placeholder":"​","style":"IPY_MODEL_d51715d4c48c4de9be759d0e7c8419e2","value":"Map: 100%"}},"02d6e2800fdc4949a8fd98ca1ce1616a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a3836644ca64d3f941b3a933ae4a583","max":773,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f8391846a7694fd1af97562895360936","value":773}},"4076f6f7080444b2816076fbff238b4b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5532ddced19b4fc4985466d35f97be9c","placeholder":"​","style":"IPY_MODEL_6f9e6d875d6d40018d2c083bcbda7774","value":" 773/773 [00:05&lt;00:00, 111.30 examples/s]"}},"40bc2c100cd4422cba87c486bba059e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15128b176c60435ca44a040bf46c2615":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d51715d4c48c4de9be759d0e7c8419e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a3836644ca64d3f941b3a933ae4a583":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8391846a7694fd1af97562895360936":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5532ddced19b4fc4985466d35f97be9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f9e6d875d6d40018d2c083bcbda7774":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["1. 安装依赖并设置环境"],"metadata":{"id":"_WxfNQMhQdlc"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Se3d9TeOQPrK","executionInfo":{"status":"ok","timestamp":1745774431839,"user_tz":-120,"elapsed":94238,"user":{"displayName":"王旭辉","userId":"00618006931554294053"}},"outputId":"93ba8eb4-5bfb-4a7c-8f3e-fe9de98f4d2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n","Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n","Collecting peft\n","  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n","Collecting datasets\n","  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n","Collecting accelerate\n","  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n","Downloading peft-0.15.2-py3-none-any.whl (411 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m119.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, bitsandbytes, accelerate, peft\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.2\n","    Uninstalling fsspec-2025.3.2:\n","      Successfully uninstalled fsspec-2025.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 1.5.2\n","    Uninstalling accelerate-1.5.2:\n","      Successfully uninstalled accelerate-1.5.2\n","  Attempting uninstall: peft\n","    Found existing installation: peft 0.14.0\n","    Uninstalling peft-0.14.0:\n","      Successfully uninstalled peft-0.14.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-1.6.0 bitsandbytes-0.45.5 datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 peft-0.15.2 xxhash-3.5.0\n","Mounted at /content/drive\n"]}],"source":["!pip install transformers peft datasets bitsandbytes accelerate -U\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"markdown","source":["2. 准备训练数据"],"metadata":{"id":"1kW3EeDMQeZD"}},{"cell_type":"code","source":["# 解压包含狗狗介绍文本的压缩包到指定文件夹\n","!unzip -q /content/wiki_dogs.zip -d /content/dogs\n","\n","import os\n","import json\n","\n","folder_path = '/content/dogs'\n","jsonl_path = '/content/dog_lora_train.jsonl'\n","train_data = []\n","\n","# 遍历文件夹中所有狗狗文本文件，构建 instruction-output 格式的数据\n","for filename in os.listdir(folder_path):\n","    if filename.endswith('.txt'):\n","        dog_name = os.path.splitext(filename)[0]  # 文件名去掉后缀作为狗狗名称\n","        file_path = os.path.join(folder_path, filename)\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            desc = f.read().strip()\n","        # 构建包含指令和回答的字典条目\n","        item = {\n","            \"instruction\": f\"介绍一下{dog_name}。\",\n","            \"input\": \"\",  # 无额外输入信息\n","            \"output\": desc\n","        }\n","        train_data.append(item)\n","\n","# 将数据保存为 JSONL 文件\n","with open(jsonl_path, 'w', encoding='utf-8') as f:\n","    for item in train_data:\n","        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n","\n","print(f\"数据集构建完成，共{len(train_data)}条示例，已保存到 {jsonl_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vB1j3mSsQb_x","executionInfo":{"status":"ok","timestamp":1745774438364,"user_tz":-120,"elapsed":308,"user":{"displayName":"王旭辉","userId":"00618006931554294053"}},"outputId":"e99bfd16-cc5d-4787-be1e-bca57aa4d73a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["数据集构建完成，共773条示例，已保存到 /content/dog_lora_train.jsonl\n"]}]},{"cell_type":"markdown","source":["3. 加载预训练模型和分词器"],"metadata":{"id":"-iSBQWWiQgnY"}},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","\n","MODEL_DIR = \"/content/drive/MyDrive/硕士第二学期/先进软件技术/DeepSeek_R1_Distill_Qwen_1_5B\"\n","\n","bnb_cfg = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_compute_dtype=\"float16\",\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_DIR,\n","    quantization_config=bnb_cfg,\n","    device_map=\"auto\",\n","    trust_remote_code=True\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\""],"metadata":{"id":"sD1lsrhGQiQK","executionInfo":{"status":"ok","timestamp":1745774775611,"user_tz":-120,"elapsed":5548,"user":{"displayName":"王旭辉","userId":"00618006931554294053"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["4. 配置 LoRA 参数"],"metadata":{"id":"cxc-tF35QrEA"}},{"cell_type":"code","source":["from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n","\n","model = prepare_model_for_kbit_training(model)\n","\n","lora_cfg = LoraConfig(\n","    r=8,\n","    lora_alpha=16,\n","    target_modules=[\"q_proj\", \"v_proj\"],\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","model = get_peft_model(model, lora_cfg)\n","model.print_trainable_parameters()  # 验证 LoRA 参数数目"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bVmwPRphQsho","executionInfo":{"status":"ok","timestamp":1745774807925,"user_tz":-120,"elapsed":100,"user":{"displayName":"王旭辉","userId":"00618006931554294053"}},"outputId":"e6cf1204-e231-49b8-f572-403781dd3169"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["trainable params: 1,089,536 || all params: 1,778,177,536 || trainable%: 0.0613\n"]}]},{"cell_type":"markdown","source":["5. 加载并预处理数据集"],"metadata":{"id":"Td4tNH05Qvbh"}},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","# ① 定义 JSONL 数据集路径\n","out_path = '/content/dog_lora_train.jsonl'\n","\n","# ② 正确加载 JSONL 数据（builder 用 \"json\"）\n","ds = load_dataset(\n","    \"json\",\n","    data_files={'train': out_path},\n","    split=\"train\"\n",")\n","\n","def preprocess_fn(example):\n","    instr = example[\"instruction\"]\n","    resp  = example[\"output\"]\n","    full  = instr + resp\n","\n","    # 对 full 文本做 分词+截断+固定长度填充\n","    tok_full = tokenizer(\n","        full,\n","        max_length=512,\n","        truncation=True,\n","        padding=\"max_length\"\n","    )\n","    input_ids    = tok_full[\"input_ids\"]\n","    attention_mask = tok_full[\"attention_mask\"]\n","\n","    # 单独分词 instruction 以获得长度\n","    tok_ins = tokenizer(instr, truncation=True, padding=False)[\"input_ids\"]\n","    ins_len = len(tok_ins)\n","\n","    # 构造 labels，instruction 部分设为 -100（不计入 loss）\n","    labels = [-100] * ins_len + input_ids[ins_len:]\n","    # 保证 labels 长度 = 512\n","    labels = labels[:512] + [-100] * max(0, 512 - len(labels))\n","\n","    return {\n","        \"input_ids\": input_ids,\n","        \"attention_mask\": attention_mask,\n","        \"labels\": labels\n","    }\n","\n","# ③ 应用预处理\n","tok_ds = ds.map(preprocess_fn, batched=False, remove_columns=ds.column_names)\n","print(\"✔ 示例预处理后：\", tok_ds[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["7a08e9460b764b06bc81d49c8d32dc58","599bb6fb5e424e428c8e287afc092218","02d6e2800fdc4949a8fd98ca1ce1616a","4076f6f7080444b2816076fbff238b4b","40bc2c100cd4422cba87c486bba059e9","15128b176c60435ca44a040bf46c2615","d51715d4c48c4de9be759d0e7c8419e2","0a3836644ca64d3f941b3a933ae4a583","f8391846a7694fd1af97562895360936","5532ddced19b4fc4985466d35f97be9c","6f9e6d875d6d40018d2c083bcbda7774"]},"id":"16bJ3WW7Qvux","executionInfo":{"status":"ok","timestamp":1745774883905,"user_tz":-120,"elapsed":5923,"user":{"displayName":"王旭辉","userId":"00618006931554294053"}},"outputId":"ac333639-bbc6-466a-82b3-9fe700755798"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/773 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a08e9460b764b06bc81d49c8d32dc58"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✔ 示例预处理后： {'input_ids': [151646, 109432, 3889, 67, 21945, 8698, 78232, 3346, 1773, 785, 3616, 67, 21945, 8698, 78232, 3346, 374, 264, 8848, 27775, 315, 7445, 504, 279, 38193, 3942, 315, 10620, 24024, 304, 10200, 37602, 932, 17689, 13, 1084, 374, 825, 315, 3040, 8606, 57145, 315, 279, 5537, 11, 279, 3800, 1660, 279, 2980, 409, 393, 5054, 8698, 11, 279, 4570, 77115, 476, 3406, 285, 446, 20172, 11, 323, 279, 16821, 64653, 78232, 3346, 382, 13424, 198, 785, 3616, 67, 21945, 8698, 78232, 3346, 11, 3156, 448, 264, 1372, 315, 15130, 27454, 1741, 438, 279, 10621, 15154, 21635, 11, 279, 42188, 21635, 11, 279, 393, 610, 3165, 11966, 81201, 11, 279, 25453, 591, 138861, 11, 6560, 1412, 504, 12590, 315, 3240, 19500, 14811, 78, 943, 24928, 1119, 10200, 37602, 932, 358, 652, 685, 323, 9806, 37602, 932, 9625, 3807, 23631, 4134, 11, 678, 11220, 1119, 12460, 4494, 4092, 311, 279, 19322, 323, 8502, 315, 2205, 9833, 5676, 624, 785, 3616, 67, 21945, 8698, 78232, 3346, 572, 1429, 16626, 1730, 304, 279, 58489, 315, 362, 2157, 89, 446, 6255, 11, 647, 12417, 653, 425, 10011, 11, 51730, 28732, 11, 444, 12707, 323, 362, 22584, 16551, 304, 279, 10620, 12452, 37794, 315, 506, 21211, 325, 13, 5542, 279, 220, 16, 24, 22, 15, 82, 78187, 11, 7214, 57145, 315, 7445, 6116, 2500, 311, 15154, 47973, 323, 5109, 315, 279, 3616, 67, 21945, 8698, 78232, 3346, 3937, 1119, 17704, 26, 419, 572, 87324, 553, 264, 17704, 304, 1346, 36877, 5109, 6814, 279, 10620, 12452, 9167, 333, 13, 2014, 5358, 279, 51509, 315, 279, 27775, 11, 279, 1850, 56649, 2058, 2500, 1033, 7407, 323, 12433, 11, 7945, 504, 279, 39921, 315, 506, 21211, 325, 323, 444, 33501, 13, 758, 220, 17, 15, 15, 16, 11, 264, 27775, 1673, 2190, 572, 9555, 311, 3255, 65682, 7858, 26, 432, 374, 8975, 553, 279, 10140, 409, 431, 12707, 653, 3616, 67, 21945, 8698, 78232, 3346, 382, 5009, 198, 785, 3616, 67, 21945, 8698, 78232, 3346, 374, 264, 11051, 27835, 27775, 315, 7445, 11, 432, 49442, 1948, 220, 17, 15, 323, 220, 18, 15, 84302, 320, 19, 19, 323, 220, 21, 21, 18866, 8, 323, 13352, 1948, 220, 20, 15, 323, 220, 20, 20, 2889, 85266, 416, 320, 17, 15, 323, 220, 17, 17, 304, 701, 12590, 525, 11136, 8131, 1091, 293, 25220, 13, 576, 27775, 702, 264, 2805, 27950, 22875, 11, 892, 1231, 387, 29552, 476, 296, 1716, 832, 293, 26463, 20394, 476, 489, 26463, 20394, 448, 894, 315, 15138, 23333, 11, 18575, 11, 50892, 323, 3691, 389, 4158, 26, 6437, 13876, 11, 13753, 476, 3691, 10295, 525, 1083, 1730, 382, 10253, 198, 785, 27775, 374, 264, 31945, 21633, 27775, 304, 429, 432, 374, 1483, 311, 19073, 11, 1459, 323, 17179, 1809, 3055, 6552, 553, 279, 39727, 13, 576, 3616, 67, 21945, 8698, 78232, 3346, 374, 1483, 46804, 311, 19073, 1809, 19654, 11, 304, 3953, 1346, 36877, 11, 922, 604, 323, 7579, 37153, 11, 7892, 432, 374, 1083, 1483, 311, 19073, 2613, 4910, 1809, 1741, 438, 94918, 323, 38724, 382, 9830, 1083, 198, 35, 26307, 23132, 198, 852, 315, 5562, 57145, 1406], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, 785, 3616, 67, 21945, 8698, 78232, 3346, 374, 264, 8848, 27775, 315, 7445, 504, 279, 38193, 3942, 315, 10620, 24024, 304, 10200, 37602, 932, 17689, 13, 1084, 374, 825, 315, 3040, 8606, 57145, 315, 279, 5537, 11, 279, 3800, 1660, 279, 2980, 409, 393, 5054, 8698, 11, 279, 4570, 77115, 476, 3406, 285, 446, 20172, 11, 323, 279, 16821, 64653, 78232, 3346, 382, 13424, 198, 785, 3616, 67, 21945, 8698, 78232, 3346, 11, 3156, 448, 264, 1372, 315, 15130, 27454, 1741, 438, 279, 10621, 15154, 21635, 11, 279, 42188, 21635, 11, 279, 393, 610, 3165, 11966, 81201, 11, 279, 25453, 591, 138861, 11, 6560, 1412, 504, 12590, 315, 3240, 19500, 14811, 78, 943, 24928, 1119, 10200, 37602, 932, 358, 652, 685, 323, 9806, 37602, 932, 9625, 3807, 23631, 4134, 11, 678, 11220, 1119, 12460, 4494, 4092, 311, 279, 19322, 323, 8502, 315, 2205, 9833, 5676, 624, 785, 3616, 67, 21945, 8698, 78232, 3346, 572, 1429, 16626, 1730, 304, 279, 58489, 315, 362, 2157, 89, 446, 6255, 11, 647, 12417, 653, 425, 10011, 11, 51730, 28732, 11, 444, 12707, 323, 362, 22584, 16551, 304, 279, 10620, 12452, 37794, 315, 506, 21211, 325, 13, 5542, 279, 220, 16, 24, 22, 15, 82, 78187, 11, 7214, 57145, 315, 7445, 6116, 2500, 311, 15154, 47973, 323, 5109, 315, 279, 3616, 67, 21945, 8698, 78232, 3346, 3937, 1119, 17704, 26, 419, 572, 87324, 553, 264, 17704, 304, 1346, 36877, 5109, 6814, 279, 10620, 12452, 9167, 333, 13, 2014, 5358, 279, 51509, 315, 279, 27775, 11, 279, 1850, 56649, 2058, 2500, 1033, 7407, 323, 12433, 11, 7945, 504, 279, 39921, 315, 506, 21211, 325, 323, 444, 33501, 13, 758, 220, 17, 15, 15, 16, 11, 264, 27775, 1673, 2190, 572, 9555, 311, 3255, 65682, 7858, 26, 432, 374, 8975, 553, 279, 10140, 409, 431, 12707, 653, 3616, 67, 21945, 8698, 78232, 3346, 382, 5009, 198, 785, 3616, 67, 21945, 8698, 78232, 3346, 374, 264, 11051, 27835, 27775, 315, 7445, 11, 432, 49442, 1948, 220, 17, 15, 323, 220, 18, 15, 84302, 320, 19, 19, 323, 220, 21, 21, 18866, 8, 323, 13352, 1948, 220, 20, 15, 323, 220, 20, 20, 2889, 85266, 416, 320, 17, 15, 323, 220, 17, 17, 304, 701, 12590, 525, 11136, 8131, 1091, 293, 25220, 13, 576, 27775, 702, 264, 2805, 27950, 22875, 11, 892, 1231, 387, 29552, 476, 296, 1716, 832, 293, 26463, 20394, 476, 489, 26463, 20394, 448, 894, 315, 15138, 23333, 11, 18575, 11, 50892, 323, 3691, 389, 4158, 26, 6437, 13876, 11, 13753, 476, 3691, 10295, 525, 1083, 1730, 382, 10253, 198, 785, 27775, 374, 264, 31945, 21633, 27775, 304, 429, 432, 374, 1483, 311, 19073, 11, 1459, 323, 17179, 1809, 3055, 6552, 553, 279, 39727, 13, 576, 3616, 67, 21945, 8698, 78232, 3346, 374, 1483, 46804, 311, 19073, 1809, 19654, 11, 304, 3953, 1346, 36877, 11, 922, 604, 323, 7579, 37153, 11, 7892, 432, 374, 1083, 1483, 311, 19073, 2613, 4910, 1809, 1741, 438, 94918, 323, 38724, 382, 9830, 1083, 198, 35, 26307, 23132, 198, 852, 315, 5562, 57145, 1406]}\n"]}]},{"cell_type":"markdown","source":["6. 设置数据整理器和训练参数"],"metadata":{"id":"tSOfOBIcQxf2"}},{"cell_type":"code","source":["from transformers import TrainingArguments, default_data_collator\n","\n","training_args = TrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/硕士第二学期/先进软件技术/lora_outputs\",\n","    per_device_train_batch_size=8,\n","    gradient_accumulation_steps=2,\n","    learning_rate=2e-4,\n","    num_train_epochs=7,\n","    logging_steps=10,\n","    save_steps=200,\n","    save_total_limit=2,\n","    bf16=True,\n","    optim=\"paged_adamw_8bit\",\n","    report_to=\"none\"\n",")\n","\n","# 使用默认 collator 即可，因为我们已静态 pad 到 max_length\n","data_collator = default_data_collator"],"metadata":{"id":"xP6eK0EfQz3b","executionInfo":{"status":"ok","timestamp":1745775420091,"user_tz":-120,"elapsed":21,"user":{"displayName":"王旭辉","userId":"00618006931554294053"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["7. 执行模型微调"],"metadata":{"id":"5fkvaWGXQ1a_"}},{"cell_type":"code","source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tok_ds,\n","    data_collator=data_collator\n",")\n","\n","trainer.train()\n","# 把 LoRA 适配器权重也保存一份\n","model.save_pretrained(training_args.output_dir)\n","print(\"✔ 微调完成，LoRA 权重保存在\", training_args.output_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"0QGcoJGUQ3Em","executionInfo":{"status":"ok","timestamp":1745775773280,"user_tz":-120,"elapsed":350660,"user":{"displayName":"王旭辉","userId":"00618006931554294053"}},"outputId":"bc4214d0-9359-459a-f766-34ccf8cf1179"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='336' max='336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [336/336 05:49, Epoch 6/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>2.866300</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>2.808100</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>2.784400</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>2.791100</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>2.769000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>2.771600</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>2.737600</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>2.690400</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>2.813300</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>2.785200</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>2.726200</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>2.732300</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>2.749600</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>2.695900</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>2.707500</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>2.700600</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>2.817000</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>2.615600</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>2.685900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>2.643300</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>2.726300</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>2.706300</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>2.615700</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>2.713500</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>2.630700</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>2.707000</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>2.653900</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>2.741400</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>2.655000</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>2.533600</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>2.741200</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>2.688200</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>2.642400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["✔ 微调完成，LoRA 权重保存在 /content/drive/MyDrive/硕士第二学期/先进软件技术/lora_outputs\n"]}]},{"cell_type":"markdown","source":["8. 合并 LoRA 权重并进行推理测试"],"metadata":{"id":"3YKYyEyzRah_"}},{"cell_type":"code","source":["import os\n","from peft import PeftModel\n","\n","# 重新加载基础模型\n","base = AutoModelForCausalLM.from_pretrained(\n","    MODEL_DIR,\n","    quantization_config=bnb_cfg,\n","    device_map=\"auto\",\n","    trust_remote_code=True\n",")\n","\n","# 自动选择最后一个 checkpoint\n","ckpts = [d for d in os.listdir(training_args.output_dir) if d.startswith(\"checkpoint\")]\n","ckpts.sort(key=lambda x: int(x.split(\"-\")[-1]))\n","lora_dir = os.path.join(training_args.output_dir, ckpts[-1]) \\\n","           if ckpts else training_args.output_dir\n","\n","print(\"加载 LoRA 权重：\", lora_dir)\n","peft_m = PeftModel.from_pretrained(base, lora_dir)\n","merged = peft_m.merge_and_unload()\n","\n","# 分词器\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","# 推理：以“萨摩耶犬”为例\n","dog = \"萨摩耶犬\"\n","inp = tokenizer(f\"介绍一下{dog}。\", return_tensors=\"pt\")\n","inp = {k: v.to(merged.device) for k, v in inp.items()}\n","out = merged.generate(**inp, max_new_tokens=256)\n","print(\"【推理结果】\", tokenizer.decode(out[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vn5BlY8URa3X","executionInfo":{"status":"ok","timestamp":1745775091823,"user_tz":-120,"elapsed":16424,"user":{"displayName":"王旭辉","userId":"00618006931554294053"}},"outputId":"63c63a88-e1f5-489b-84e1-f6af73168f65"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["加载 LoRA 权重： /content/drive/MyDrive/硕士第二学期/先进软件技术/lora_outputs/checkpoint-144\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:351: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n","  warnings.warn(\n","Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["【推理结果】 介绍一下萨摩耶犬。包括它们的特征，繁殖方式，以及它们的习性。\n","</think>\n","\n","萨摩耶犬（Sphynx）是一种大型犬，属于犬科的萨摩耶犬属。萨摩耶犬是一种广受欢迎的宠物犬，因其独特的外观、灵活的繁殖方式以及丰富的习性而受到喜爱。以下是关于萨摩耶犬的详细介绍：\n","\n","### 1. 特征\n","- **体型**：萨摩耶犬的体形呈椭圆形，通常以长耳和发黑皮为特征。它的体长通常在16-22厘米之间。\n","- **颜色**：萨摩耶犬的皮色多样，通常以发黑皮为主，但也有部分发白皮和黑色皮。\n","- **特征**：萨摩耶犬通常拥有长耳，耳后有黑色皮，皮上有一道凹槽，两侧有细长的指纹。它的皮质较为光滑，皮质通常为发黑皮，但也有部分发白皮。\n","- **毛发**：萨摩耶犬的毛发通常是发黑皮，部分发白皮，但通常较薄。它的毛发部分主要分布在头部和面部，而发白皮通常集中在耳\n"]}]},{"cell_type":"markdown","source":["保存融合后的模型"],"metadata":{"id":"azU9LZaCW5SH"}},{"cell_type":"code","source":["# 指定保存路径\n","save_dir = \"/content/drive/MyDrive/硕士第二学期/先进软件技术/Lora+_DeepSeek_R1_Distill_Qwen_1_5B\"\n","\n","# 保存融合后的模型权重\n","merged.save_pretrained(save_dir)\n","\n","# 同步保存分词器设置（可选，但推荐保留）\n","tokenizer.save_pretrained(save_dir)\n","\n","print(f\"✔ 融合后模型已保存到: {save_dir}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rd0nTHR1W7bV","executionInfo":{"status":"ok","timestamp":1745776007546,"user_tz":-120,"elapsed":4191,"user":{"displayName":"王旭辉","userId":"00618006931554294053"}},"outputId":"8da9e8e2-8712-4d3e-8b9d-c2b8ebbbb056"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["✔ 融合后模型已保存到: /content/drive/MyDrive/硕士第二学期/先进软件技术/Lora+_DeepSeek_R1_Distill_Qwen_1_5B\n"]}]}]}